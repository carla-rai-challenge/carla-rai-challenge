[
{
	"uri": "/basics/",
	"title": "RAI Leaderboard",
	"tags": [],
	"description": "",
	"content": "The CARLA AD Leaderboard challenges AD agents to drive through a set of predefined routes. For each route, agents will be initialized at a starting point and directed to drive to a destination point, provided with a description of the route through GPS style coordinates, map coordinates or route instructions. Routes are defined in a variety of situations, including freeways, urban areas, residential districts and rural settings. The Leaderboard evaluates AD agents in a variety of weather conditions, including daylight scenes, sunset, rain, fog, and night, among others.\nScenarios Agents will face multiple traffic scenarios based on the NHTSA typology. Scenarios are a subset of the original Carla challenge scenarios.\n Lane merging. Lane changing. Negotiations at traffic intersections. Negotiations at roundabouts. Handling traffic lights and traffic signs. Yielding to emergency vehicles. Coping with pedestrians, cyclists, and other elements.  Below are illustrations of traffic situations that could be present in the RAI AD challenge: Participation Modalities Unlike the original Carla AD challenge, our leaderboard only offers one participation modality, which is the SENSORS modality. Agents will receive a high-level route description indicating the key points that the path has to follow in order to reach the destination. The route is represented as a list of tuples and has two variations.\nFor the first case, the first element of the tuple contains a waypoint, expressed as a latitude, a longitude, and a z component.\n[({'z': 0.0, 'lat': 48.99822669411668, 'lon': 8.002271601998707}, RoadOption.LEFT), ({'z': 0.0, 'lat': 48.99822669411668, 'lon': 8.002709765148996}, RoadOption.RIGHT), ... ({'z': 0.0, 'lat': 48.99822679980298, 'lon': 8.002735250105061}, RoadOption.STRAIGHT)] The second case is very similar to the previous one, but instead of using GPS coordinates, the route is expressed in world coordinates instead.\n[({'x': 153.7, 'y': 15.6, 'z': 0.0}, RoadOption.LEFT), ({'x': 148.9, 'y': 67.8, 'z': 0.0}, RoadOption.RIGHT), ... ({'x': 180.7, 'y': 45.1, 'z': 1.2}, RoadOption.STRAIGHT)]  The distance between two consecutive waypoints could be up to hundreds of meters. Do not rely on these as your principal mechanism to navigate the environment.\n The second element contains a high-level command. The set of available high-level commands is:\n RoadOption.CHANGELANELEFT: Move one lane to the left. RoadOption.CHANGELANERIGHT: Move one lane to the right. RoadOption.LANEFOLLOW: Continue in the current lane. RoadOption.LEFT: Turn left at the intersection. RoadOption.RIGHT: Turn right at the intersection. RoadOption.STRAIGHT: Keep straight at the intersection.  There might be cases where the semantics of left and right is ambiguous. In order to disambiguate these situations, you could consider the GPS position of the next waypoints.\nYou are not allowed to make use of any privilege information offered by the CARLA simulator, including planners or any type of ground truth. Submissions using these features will be rejected and teams will be banned from the platform.\n Sensors Available Agents can request access to the following sensors:\n   GNSS IMU LIDAR RADAR RGB Camera Speedometer     sensor.other.gnss sensor.other.imu sensor.lidar.ray_cast sensor.other.radar sensor.camera.rgb sensor.other.speedometer   0-1 units 0-1 units 0-1 units 0-2 units 0-4 units 0-1 units   GPS sensor returning geo location data. 6-axis Inertial Measurement Unit. Velodyne 64 LIDAR Long-range RADAR (up to 100 meters). Regular camera that captures images. Pseudosensor that provides an approximation of your linear velocity.    Evaluation and Metrics The driving proficiency of an agent can be characterized by multiple metrics. For this leaderboard we have selected a set of metrics that help understand different aspects of driving. While all routes have the same type of metrics, their respective values are calculated separately. The specific metrics are as follows:\n  Driving score: R_i P_i,— Main metric of the leaderboard, serving as the product between the route completion and the infractions penalty. Here R_i is the percentage of completion of the i − th route, and P_i, the infraction penalty of the i − th route.\n  Route completion: Percentage of the route distance completed by an agent.\n  Infraction penalty: ∏^(ped., \u0026hellip;, stop)_j((P_i)^i)(#infractions)_j — The leaderboard tracks several types of infractions and this metric aggregates all of these infractions triggered by an agent as a geometric series. Agents start with an ideal 1.0 base score, which is reduced each type an infraction is commited.\n  When all routes have been completed, a global metric for each of the previous three types is also generated, being the arithmetic mean of all the individual routes combined. The global driving score is the main metric on which you will be classified with respect to other participants.\nInfractions and shutdown events The CARLA leaderboard offers individual metrics for a series of infractions. Each of these has a penalty coefficient that will be applied everytime it happens. Ordered by severity, the infractions are the following.\n Collisions with pedestrians — 0.50. Collisions with other vehicles — 0.60. Collisions with static elements — 0.65. Running a red light — 0.70. Running a stop sign — 0.80.  Some scenarios feature behaviors that can block the ego-vehicle indefinitely. These scenarios will have a timeout of 4 minutes after which the ego-vehicle will be released to continue the route. However, a penalty is applied when the time limit is breached:\n Scenario timeout — 0.7  The agent is expected to maintain a minimum speed in keeping with nearby traffic. The agent’s speed will be compared with the speed of nearby vehicles. Failure to maintain a suitable speed will result in a penalty. The penalty applied is dependent on the magnitude of the speed difference, up to the following value:\n Failure to maintain minimum speed — 0.7  The agent should yield to emergency vehicles coming from behind. Failure to allow the emergency vehicle to pass will incur a penalty:\n Failure to yield to emergency vehicle — 0.7  Besides these, there is one additional infraction which has no coefficient, and instead affects the computation of the route completion (R_i).\n  Off-road driving — If an agent drives off-road, that percentage of the route will not be considered towards the computation of the route completion score. Additionally, some events will interrupt the simulation, preventing the agent to continue. In these cases, the route which is being simulated will be shut down, and the leaderboard will move onto the next one, triggering it normally.\n  Route deviation — If an agent deviates more than 30 meters from the assigned route.\n  Agent blocked — If an agent doesn’t take any actions for 180 simulation seconds.\n  Simulation timeout — If no client-server communication can be established in 60 seconds.\n  Route timeout — If the simulation of a route takes too long to finish.\n  Each time any of the above happens, several details are recorded, which will be displayed as a list for you to see at the route’s individual metrics. Below is an example of a route where the agent both run a red light and deviated from the route.\n\u0026quot;infractions\u0026quot;: { \u0026quot;Collisions with layout\u0026quot;: [], \u0026quot;Collisions with pedestrians\u0026quot;: [], \u0026quot;Collisions with vehicles\u0026quot;: [], \u0026quot;Red lights infractions\u0026quot;: [ \u0026quot;Agent ran a red light 203 at (x=341.25, y=209.1, z=0.104)\u0026quot; ], \u0026quot;Stop sign infractions\u0026quot;: [], \u0026quot;Off-road infractions\u0026quot;: [], \u0026quot;Min speed infractions\u0026quot;: [], \u0026quot;Yield to emergency vehicle infractions\u0026quot;: [], \u0026quot;Scenario timeouts\u0026quot;: [], \u0026quot;Route deviations\u0026quot;: [ \u0026quot;Agent deviated from the route at (x=95.92, y=165.673, z=0.138)\u0026quot; ], \u0026quot;Agent blocked\u0026quot;: [], \u0026quot;Route timeouts\u0026quot;: [] }  The global infractions compress the individual route’s data into a single value and is given as the number of events per Km.\n "
},
{
	"uri": "/create/",
	"title": "Creating an Agent",
	"tags": [],
	"description": "",
	"content": "1. System Setup 1.1 Get CARLA 0.9.10.1   Download the binary CARLA 0.9.10.1 release.\n  Unzip the package into a folder, e.g. CARLA.\n  In the following commands, change the ${CARLA_ROOT} variable to correspond to your CARLA root folder.\n  In order to use the CARLA Python API you will need to install some dependencies in your favorite environment. As a reference, for conda, start by creating a new environment:  conda create -n py37 python=3.7 conda activate py37 cd ${CARLA_ROOT} # Change ${CARLA_ROOT} for your CARLA root folder pip3 install -r PythonAPI/carla/requirements.txt  Download the set of additional maps to extend the amount of training data available. Follow the instructions provided here to install these maps.  Make sure to download 0.9.10.1 and its corresponding maps. This is the exact version used by the online servers.\n 1.2 Get the Leaderboard and Scenario_Runner  Download the Leaderboard repository.(REMEBER TO UPDATE LINK)  git clone -b leaderboard-1.0 --single-branch https://github.com/carla-simulator/leaderboard.git  In the following commands, change the ${LEADERBOARD_ROOT} variable to correspond to your Leaderboard root folder.\n  Install the required Python dependencies.  cd ${LEADERBOARD_ROOT} # Change ${LEADERBOARD_ROOT} for your Leaderboard root folder pip3 install -r requirements.txt  Download the Scenario_Runner repository.  git clone -b leaderboard --single-branch https://github.com/carla-simulator/scenario_runner.git  In the following commands, change the ${SCENARIO_RUNNER_ROOT} to correspond to your Scenario_Runner root folder.\n  Install the required Python dependencies using the same Python environments.  cd ${SCENARIO_RUNNER_ROOT} # Change ${SCENARIO_RUNNER_ROOT} for your Scenario_Runner root folder pip3 install -r requirements.txt 1.3 Define the environment variables We need to make sure that the different modules can find each other.\n Open the ~/.bashrc profile with the following command:  gedit ~/.bashrc  Edit your ~/.bashrc profile, adding the definitions below. Save and close the file after editing.  export CARLA_ROOT=PATH_TO_CARLA_ROOT export SCENARIO_RUNNER_ROOT=PATH_TO_SCENARIO_RUNNER export LEADERBOARD_ROOT=PATH_TO_LEADERBOARD export PYTHONPATH=\u0026quot;${CARLA_ROOT}/PythonAPI/carla/\u0026quot;:\u0026quot;${SCENARIO_RUNNER_ROOT}\u0026quot;:\u0026quot;${LEADERBOARD_ROOT}\u0026quot;:\u0026quot;${CARLA_ROOT}/PythonAPI/carla/dist/carla-0.9.10-py3.7-linux-x86_64.egg\u0026quot;:${PYTHONPATH}  Remember to source ``.bashrc` for these changes to take effect using the following command:  source ~/.bashrc\n2. Create Autonomous Agents with the Leaderboard 2.1 First steps with the Leaderboard The Leaderboard will take care of running your autonomous agent and evaluate its behavior in different traffic situations across multiple routes. To better understand this process, let’s run a basic agent.\n Run the CARLA server in one terminal.  cd ${CARLA_ROOT} ./CarlaUE4.sh -quality-level=Epic -world-port=2000 -resx=800 -resy=600  In another terminal, navigate to the ${LEADERBOARD_ROOT}. While the Leaderboard is run using a python script, the amount of arguments used can make it quite uncomfortable to directly do so using the terminal. Therefore, it is recommended to use a bash script:  touch test_run.sh chmod +x test_run.sh  Paste the following code into test_run.sh. This will set some environment variables for parameterization, and run the run_evaluation.sh REMEMBER TO UPDATE LINK, which will use these variables as arguments to the leaderboard_evaluator.py script.  # Parameterization settings. These will be explained in 2.2. Now simply copy them to run the test. export SCENARIOS=${LEADERBOARD_ROOT}/data/all_towns_traffic_scenarios_public.json export ROUTES=${LEADERBOARD_ROOT}/data/routes_devtest.xml export REPETITIONS=1 export DEBUG_CHALLENGE=1 export TEAM_AGENT=${LEADERBOARD_ROOT}/leaderboard/autoagents/human_agent.py export CHECKPOINT_ENDPOINT=${LEADERBOARD_ROOT}/results.json export CHALLENGE_TRACK_CODENAME=SENSORS ./scripts/run_evaluation.sh  Run the script:  ./test_run.sh This will launch a pygame window giving you the option to manually control an agent. Follow the route indicated by colorful waypoints in order to get to your destination. The script cycles through 6 towns, loading a single test route in each one.\nManually interrupting the Leaderboard will preemptively stop the simulation of the route, automatically moving onto the next one.\n 2.2 Understanding the Leaderboard components When running the test, we set a series of parameters. Let’s understand these and their role in the Leaderboard.\n  SCENARIOS (JSON) — The set of scenarios that will be tested in the simulation. A scenario is defined as a traffic situation. Agents will have to overcome these scenarios in order to pass the test. Participants have access to a set of traffic scenarios that work on the publicly available towns. There are 10 types of scenarios that are instantiated using different parameters. Here is a list of the available scenarios.\n  ROUTES (XML) — The set of routes that will be used for the simulation. Every route has a starting point (first waypoint), and an ending point (last waypoint). Additionally, they can contain a weather profile to set specific weather conditions. A XML contains many routes, each one with an ID. Users can modify, add, and remove routes for training and validation purposes. The Leaderboard ships with a set of routes for debug, training, and validation. The routes used for the online evaluation are secret.\n  REPETITIONS (int) — Number of times each route is repeated for statistical purposes.\n  TEAM_AGENT (Python script) — Path to the Python script that launches the agent. This has to be a class inherited from leaderboard.autoagents.autonomous_agent.AutonomousAgent. The steps to create an agent are explained in the next step.\n  Other relevant parameters are described below.\n  TEAM_CONFIG (defined by the user) — Path to an arbitrary configuration file read by the provided agent. You are responsible to define and parse this file within your agent class.\n  DEBUG_CHALLENGE (int) — Flag that indicates if debug information should be shown during the simulation. By default this variable is unset (0), which produces no debug information to be displayed. When this is set to 1, the simulator will display the reference route to be followed. If this variable is set to anything greater than 1 the engine will print the complete state of the simulation for debugging purposes.\n  CHECKPOINT_ENDPOINT (JSON) — The name of a file where the Leaderboad metrics will be recorded.\n  RECORD_PATH (string) — Path to a folder that will store the CARLA logs. This is unset by default. RESUME — Flag to indicate if the simulation should be resumed from the last route. This is unset by default.\n  These environment variables are passed to ${LEADERBOARD_ROOT}/leaderboard/leaderboard_evaluator.py, which serves as the entry point to perform the simulation. Take a look at leaderboard_evaluator.py to find out more details on how your agent will be executed and evaluated.\n3. Creating your own Autonomous Agent The definition of a new agent starts by creating a new class that inherits from leaderboard.autoagents.autonomous_agent.AutonomousAgent.\n3.1 Create get_entry_point First, define a function called get_entry_point that returns the name of your new class. This will be used to automatically instantiate your agent.\nfrom leaderboard.autoagents.autonomous_agent import AutonomousAgent def get_entry_point(): return 'MyAgent' class MyAgent(AutonomousAgent): ... 3.2 Override the setup method Within your agent class override the setup method. This method performs all the initialization and definitions needed by your agent. It will be automatically called each time a route is initialized. It can receive an optional argument pointing to a configuration file. Users are expected to parse this file.\nfrom leaderboard.autoagents.autonomous_agent import Track ... def setup(self, path_to_conf_file): self.track = Track.SENSORS # At a minimum, this method sets the Leaderboard modality. In this case, SENSORS 3.3 Override the sensors method You will also have to override the sensors method, which defines all the sensors required by your agent.\ndef sensors(self): sensors = [ {'type': 'sensor.camera.rgb', 'id': 'Center', 'x': 0.7, 'y': 0.0, 'z': 1.60, 'roll': 0.0, 'pitch': 0.0, 'yaw': 0.0, 'width': 300, 'height': 200, 'fov': 100}, {'type': 'sensor.lidar.ray_cast', 'id': 'LIDAR', 'x': 0.7, 'y': -0.4, 'z': 1.60, 'roll': 0.0, 'pitch': 0.0, 'yaw': -45.0}, {'type': 'sensor.other.radar', 'id': 'RADAR', 'x': 0.7, 'y': -0.4, 'z': 1.60, 'roll': 0.0, 'pitch': 0.0, 'yaw': -45.0, 'fov': 30}, {'type': 'sensor.other.gnss', 'id': 'GPS', 'x': 0.7, 'y': -0.4, 'z': 1.60}, {'type': 'sensor.other.imu', 'id': 'IMU', 'x': 0.7, 'y': -0.4, 'z': 1.60, 'roll': 0.0, 'pitch': 0.0, 'yaw': -45.0}, {'type': 'sensor.opendrive_map', 'id': 'OpenDRIVE', 'reading_frequency': 1}, {'type': 'sensor.speedometer', 'id': 'Speed'}, ] return sensors  Most of the sensor attributes have fixed values. These can be checked in agent_wrapper.py. This is done so that all the teams compete within a common sensor framework.\n Every sensor is represented as a dictionary, containing the following attributes:\n type: type of the sensor to be added. id: the label that will be given to the sensor to be accessed later. other attributes: these are sensor dependent, e.g.: extrinsics and fov.  Users can set both intrinsics and extrinsic parameters (location and orientation) of each sensor, in relative coordinates with respect to the vehicle. Please, note that CARLA uses the Unreal Engine coordinate system, which is: x-front, y-right, z-up.\nThe available sensors are:\n sensor.camera.rgb — Regular camera that captures images. sensor.lidar.ray_cast — Velodyne 64 LIDAR. sensor.other.radar — Long-range RADAR (up to 100 meters). sensor.other.gnss — GPS sensor returning geo location data. sensor.other.imu — 6-axis Inertial Measurement Unit. sensor.speedometer — Pseudosensor that provides an approximation of your linear velocity.  Trying to set another sensor or misspelling these, will make the set up fail.\n You can use any of these sensors to configure your sensor stack. However, in order to keep a moderate computational load we have set the following limits to the number of sensors that can be added to an agent:\n sensor.camera.rgb: 4 sensor.lidar.ray_cast: 1 sensor.other.radar: 2 sensor.other.gnss: 1 sensor.other.imu: 1 sensor.opendrive_map: 1 sensor.speedometer: 1  Trying to set too many units of a sensor will make the set up fail.\n There are also spatial restrictions that limit the placement of your sensors within the volume of your vehicle. If a sensor is located more than 3 meters away from its parent in any axis (e.g. [3.1,0.0,0.0]), the setup will fail.\n3.4 Override the run_step method This method will be called once per time step to produce a new action in the form of a carla.VehicleControl object. Make sure this function returns the control object, which will be use to update your agent.\ndef run_step(self, input_data, timestamp): control = self._do_something_smart(input_data, timestamp) return control   input_data: A dictionary containing sensor data for the requested sensors. The data has been preprocessed at REMEMBER TO UPDATE LINK sensor_interface.py, and will be given as numpy arrays. This dictionary is indexed by the ids defined in the sensor method.\n  timestamp: A timestamp of the current simulation instant.\n  Remember that you also have access to the route that the ego agent should travel to achieve its destination. Use the self._global_plan member to access the geolocation route and self._global_plan_world_coord for its world location counterpart.\n3.5 Override the destroy method At the end of each route, the destroy method will be called, which can be overriden by your agent, in cases where you need a cleanup. As an example, you can make use of this function to erase any unwanted memory of a network\ndef destroy(self): pass 3.6 ROS based agents In case you want to use ROS as part of your agent, here are some recommendations to take into account:\n ROS Melodic: Due to the leaderboard being only compatible with Python 3, we recommend using roslibpy to communicate between the leaderboard and your ROS stack. ROS Noetic: As ROS Noetic is targetting Python 3, you can directly use rospy to create a node to communicate the leaderboard with your ROS stack. ROS2 Foxy: Similar to ROS Noetic, you can directly use rclpy to establish the communication with your stack.  4. Training and testing your agent We have prepared a set of predefined routes to serve as a starting point. You can use these routes for training and verifying the performance of your agent. Routes can be found in the folder {LEADERBOARD_ROOT}/data:\nroutes_training.xml: 50 routes intended to be used as training data (112.8 Km). routes_testing.xml: 26 routes intended to be used as verification data (58.9 Km).\n4.1 Baselines Brady Zhou has created a wonderful starter kit based on the Learning by Cheating approach.\n"
},
{
	"uri": "/submission/",
	"title": "Submitting an Agent",
	"tags": [],
	"description": "",
	"content": " By submitting your agent to the CARLA Autonomous Driving Leaderboard you are accepting the terms of use.\n General steps In order to create and submit your agent you should have a copy of the leaderboard project and scenario_runner. If this is not the case, please visit the Get started section first.\n1. Create a dockerfile to build your agent In order for the CARLA leaderboard to evaluate your agent, it needs to be encapsulated within a docker image. For a successful one, you will have to be able to run your agent with the leaderboard inside your docker. You can either create your image from scratch, or follow the guidelines below:\n  Create a new directory to host your code. For a submission to be valid, it is necessary to create this directory outside the ${LEADERBOARD_ROOT}. We will refer to this directory as ${TEAM_CODE_ROOT}.\n  Find the dockerfile at ${LEADERBOARD_ROOT}/scripts/Dockerfile.master. This template serves as a starting point for users. Here all the dependecies needed for scenario runner and leaderboard have already been set up. Include the dependencies and additional packages required by your agent. We recommend you add the new commands in the area delimited by the tags “BEGINNING OF USER COMMANDS” and “END OF USER COMMANDS”.\n  Update the variable TEAM_AGENT to set your agent file, i.e. the entry file that inherits from AutonomousAgent. Do not change the rest of the path “/workspace/team_code“. If your agent needs a configuration file for initialization, set the variable TEAM_CONFIG to the configuration file.\n  Make sure anything you want to source is inside ${HOME}/agent_sources.sh as sources added anywhere else will not be invoked. This file is automatically sourced before running the agent in the cloud.\nPlease take note that any changes you make to the Leaderboard or Scenario Runner repositories will be overwritten when you submit your entry to the cloud.\n 1.1 ROS Stacks As stated above, all sources have to be inside ${HOME}/agent_sources.sh. In order to source ROS, you can add the following command to your Dockerfile, which creates the file and sources the ROS environment:\nRUN /bin/echo \\ 'source /opt/ros/$ROS_DISTRO/setup.bash; \\ source $TEAM_CODE_ROOT/install/setup.bash;' \u0026gt;\u0026gt; ${HOME}/agent_sources.sh  This is a template to source the ROS environment and your agent. Feel free to modify it in case your setup is different\n 2. Build your agent into a docker image Once the dockerfile is ready, make sure that all the needed environment variables are correctly defined, i.e. ${CARLA_ROOT}, ${SCENARIO_RUNNER_ROOT}, ${LEADERBOARD_ROOT}, and ${TEAM_CODE_ROOT}. The simplest way to do so is to add them to your ${HOME}/.bashrc file.\nexport CARLA_ROOT=... export SCENARIO_RUNNER_ROOT=... export LEADERBOARD_ROOT=... export TEAM_CODE_ROOT=... Feel free to adjust this script to copy additional files and resources as you see fit.\nThen, invoke the make_docker.sh utility as follows:\n${LEADERBOARD_ROOT}/scripts/make_docker.sh This will generate your docker image, creating the docker image under the name leaderboard-user.\nYou can test your docker image by running the leaderboard locally at your computer\n 3. Register a new user at Eval AI Our partners at Eval AI have developed the user interface for the leaderboard. To make a submission you need to register a user on the website. Make sure to fill in your affiliation, otherwise you may not be accepted to participate in the challenge.\n4. Create a new team After registering a user at Eval AI create a new team by clicking in the Participant Teams section as shown below. All participants need to register a team in the RAI CARLA Leaderboard. 5. Apply to the CARLA Leaderboard Go to the All Challenges section and find the CARLA Leaderboard challenge, or use this link REMEBER TO UPDATE LINK. Select Participate, then choose one of your participant teams to apply to the challenge. You will need to wait for your team to be verified by the RAI CARLA Leaderboard admins. Once your team is verified, you can start to make submissions. 6. Make your submission Once your team has been verified, you will be able to submit. In the Overview tab you will find general information about the CARLA leaderboard, got to the Submit section to make your submission. There you will find instructions to submit.\nYou will need to install the EvalAI CLI with pip:\npip install evalai Next, you need to identify your user with your token using the following command:\nevalai set_token \u0026lt;token\u0026gt; You can retrieve your token from the Submit section of the EvalAI website. You may copy and paste the command directly from the submission instructions: Please note that the token is specific to your user, each user will see a different token in this section of the website. Do not share tokens or there will be confusion over the submission author.\n Use the following command to push your Docker image:\nevalai push \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; Congratulations! You have now made a submission to the RAI CARLA Leaderboard challenge.\n"
},
{
	"uri": "/terms/",
	"title": "Terms &amp; Conditions",
	"tags": [],
	"description": "",
	"content": " Updated November 2nd, 2023.\n PLEASE READ THESE TERMS CAREFULLY. SUBMITTING TO THIS LEADERBOARD CONSTITUTES YOUR ACCEPTANCE OF THESE TERMS. IF YOU DO NOT AGREE TO ANY PART OF THESE TERMS, PLEASE DO NOT SUBMIT.\n1. How can I participate in the leaderboard? You can participate in the CARLA leaderboard as an individual or as a member of a team. Individuals may form a team with multiple members. The affiliation of each individual must be declared in order to validate and approve your team. Members without a valid affiliation will be banned from the team. The CARLA organization reserves the right to ban team members and even the entire team if any the terms of the leaderboard are violated.\nTeams can make as many submissions as they wish until they reach their allocated simulation budget or their monthly maximum number of submissions. The organization of the CARLA leaderboard reserves the right to provide teams with additional simulation budget and/or number of submissions.\n2. Submissions By making a submission to the CARLA leaderboard you and your team grant the CARLA leaderboard organization the rights to review and analyze your submission to verify that it complies with all the rules of this leaderboard. The submitted code (docker image) will be used for evaluation purposes only and will not be disclosed without the consent of the team.\n3. Disqualification You are not allowed to make use of any privilege information offered by the CARLA simulator or derivatives, including world coordinates, planners, or any type of ground truth. Submissions using these features will be rejected and teams will be banned from the platform.\nIf the organization of the CARLA leaderboard detects any infraction of these terms, an attempt to bypass the rules of the leaderboard, or any other behavior that could be perceived as dishonest, the organization reserves the right to disqualify a submission and/or ban you and/or your team members from the participation in the CARLA leaderboard.\n"
},
{
	"uri": "/",
	"title": "Carla RAI Challenge",
	"tags": [],
	"description": "",
	"content": "Overview The past few years have been characterised by the rapid development of sophisticated AI models along with rising ethical and societal concerns. This leaves us with the difficult puzzle of optimising for performance without compromising core responsible AI principles such as, transparency, robustness, environmental sustainability, etc. We conceptualise Responsible AI (RAI) as the conscious effort in designing, developing, and deploying artificial intelligence (AI) systems in a way that maximises their benefits while minimising their risks. This challenge builds upon the previous Carla Challenges. Added to the existing performance assessment metric, we implement new ways to also assess and quantifying different responsible AI concepts such as transparency, robustness and sustainabiliy.\nCarla Responsible AI Challenge assesses the transparency, robustness, and sustainability (carbon emissions) of the submitted agents. See instructions on how to get started\n Steps  Understand the Leaderboard Understand the Terms and Conditions Develop your agent Submit your agent  "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/credits/",
	"title": "Credits",
	"tags": [],
	"description": "",
	"content": "Contributors Thanks to them for making Open Source Software a better place !\nAnd a special thanks to @vjeantet for his work on docdock, a fork of hugo-theme-learn. v2.0.0 of this theme is inspired by his work.\nPackages and libraries  mermaid - generation of diagram and flowchart from text in a similar manner as markdown font awesome - the iconic font and CSS framework jQuery - The Write Less, Do More, JavaScript Library lunr - Lunr enables you to provide a great search experience without the need for external, server-side, search services\u0026hellip; horsey - Progressive and customizable autocomplete component clipboard.js - copy text to clipboard highlight.js - Javascript syntax highlighter modernizr - A JavaScript toolkit that allows web developers to use new CSS3 and HTML5 features while maintaining a fine level of control over browsers that don\u0026rsquo;t support  Tooling  Netlify - Continuous deployement and hosting of this documentation Hugo  "
},
{
	"uri": "/showcase/",
	"title": "Speaker Gallery",
	"tags": [],
	"description": "",
	"content": "This is the gallery of conference speakers:\n"
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]